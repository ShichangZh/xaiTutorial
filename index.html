<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="A Wholistic Look at the State-of-the-art of Explainable AI for Text">
  <meta name="keywords" content="XAI, Explainable AI, NLP, Natural Language Processing">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Explain AI Models: Methods and Opportunities in Explainable AI, Data-Centric AI, and Mechanistic Interpretability</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="index.html">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>
      <a class="navbar-item" href="biographies.html">
        Presenters
      </a>
      <a class="navbar-item" href="references.html">
        References
      </a>
    </div>
  </div>
</nav>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <h1 class="title is-3 publication-title">Explain AI Models: Methods and Opportunities in<br>Explainable AI, Data-Centric AI, and Mechanistic Interpretability</h1>
        <div class="is-size-5 publication-authors">
          <p>NeurIPS 2025 Tutorial</p>
        </div>
      </div>
    </div>

    <!-- Speakers. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-centered">
          <div class="columns is-centered">
            <div class="column">
              <div class="content">
                <img src="imgs/shichang.jpg" alt="Shichang Zhang" style="border-radius: 50%; width: 150px; height: 150px;">
                <p><a href="https://shichangzh.github.io/">Shichang Zhang</a><br>Harvard University</p>
              </div>
            </div>
            <div class="column">
              <div class="content">
                <img src="imgs/hima.jpg" alt="Himabindu Lakkaraju" style="border-radius: 50%; width: 150px; height: 150px;">
                <p><a href="https://himalakkaraju.github.io/">Himabindu Lakkaraju</a><br>Harvard University</p>
              </div>
            </div>
            <div class="column">
              <div class="content">
                <img src="imgs/julius.jpg" alt="Julius Adebayo" style="border-radius: 50%; width: 150px; height: 150px;">
                <p><a href="https://juliusadebayo.com/">Julius Adebayo</a><br>Guide Labs</p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!--/ Speakers. -->

    <div class="column has-text-centered">
      <div class="publication-links">
        <!-- Slides Link. -->
        <span class="link-block">
          <a href="" class="external-link button is-normal is-rounded is-dark" disabled>
            <span class="icon">
                <i class="fas fa-file-powerpoint"></i>
            </span>
            <span>Slides</span>
          </a>
        </span>
        <!-- Recording Link. -->
        <span class="link-block">
          <a href="" class="external-link button is-normal is-rounded is-dark" disabled>
            <span class="icon">
                <i class="fas fa-video"></i>
            </span>
            <span>Recording</span>
          </a>
        </span>
        <!-- Previous Version Link. -->
        <span class="link-block">
          <a href="https://explainml-tutorial.github.io/neurips20" class="external-link button is-normal is-rounded is-dark">
            <span class="icon">
                <i class="fas fa-arrow-left"></i>
            </span>
            <span>Previous Version</span>
          </a>
        </span>
      </div>
    </div>

    <!-- Overview. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <p>
              Understanding AI system behavior has become critical for safety, trust, and effective deployment across diverse applications. Three major research communities have emerged to address this challenge through interpretability methods: Explainable AI focuses on feature attribution to understand which input features drive model decisions; Data-Centric AI emphasizes data attribution to analyze how training examples shape model behavior; and Mechanistic Interpretability examines component attribution to understand how internal model components contribute to outputs. These three branches share the goal of better understanding AI systems across different aspects and differ primarily in their perspectives rather than techniques. This tutorial begins with foundational concepts and historical context, providing essential background on why explainability matters and how the field has evolved since its early days. The first technical deep dive covers post hoc explanation methods, data-centric explanation techniques, mechanistic interpretability approaches, and presents a unified framework demonstrating that these methods share fundamental techniques such as perturbations, gradients, and local linear approximations. The second technical deep dive explores inherently interpretable models, clarifying concepts like reasoning (chain-of-thought) LLMs and self-explanatory LLMs in the context of explainability, and techniques for building inherently interpretable LLMs. We also showcase open source tools that make these methods accessible to practitioners. Furthermore, we highlight promising future research directions in interpretability research and the induced future directions in AI more broadly, with applications in model editing, steering, and regulation. Through comprehensive coverage of algorithms, real-world case studies, and practical guidance, attendees will gain both a deep technical understanding of state-of-the-art methods and practical skills to apply interpretability techniques effectively in AI applications.
          </p>
        </div>
      </div>
    </div>
    <!--/ Overview. -->

    <!-- Schedule. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Schedule</h2>
        <div class="content has-text-justified">
          <ul>
            <li><strong>Introduction: Why Explainability</strong> (5 minutes)</li>
            <li><strong>History and Pre-2015 Research</strong> (10 minutes)</li>
            <li><strong>Technical Deep Dive 1</strong> (50 minutes)
              <ul>
                <li>Post hoc Explanation</li>
                <li>Data-Centric Explanation</li>
                <li>Mechanistic Interpretability</li>
                <li>A Unified View of Explainability</li>
              </ul>
            </li>
            <li><strong>Break and Q&A</strong> (15 minutes)</li>
            <li><strong>Technical Deep Dive 2</strong> (40 minutes)
              <ul>
                <li>Inherently Interpretable Models</li>
                <li>Reasoning (Chain-Of-Thought) LLMs And "Self-Explanatory" LLMs</li>
                <li>Inherently Interpretable LLMs</li>
              </ul>
            </li>
            <li><strong>Open Source Tools</strong> (10 minutes)</li>
            <li><strong>Conclusion and Future Directions</strong> (10 minutes)</li>
          </ul>
        </div>
      </div>
    </div>
    <!--/ Schedule. -->

    <!-- Citation. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Citation</h2>
        <div class="content has-text-justified">
          <p>If you find this tutorial useful, please cite:</p>
          <pre style="background-color: #f5f5f5; padding: 1rem; border-radius: 4px; text-align: left; overflow-x: auto;">
@misc{zhang2025xai,
    title={Explain AI Models: Methods and Opportunities in Explainable AI, Data-Centric AI, and Mechanistic Interpretability},
    author={Zhang, Shichang and Lakkaraju, Hima and Adebayo, Julius},
    year={2025},
    howpublished={NeurIPS 2025 Tutorial},
    url={https://your-tutorial-website.com}
}</pre>
        </div>
      </div>
    </div>
    <!--/ Citation. -->

  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
