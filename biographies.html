<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="A Wholistic Look at the State-of-the-art of Explainable AI for Text">
  <meta name="keywords" content="XAI, Explainable AI, NLP, Natural Language Processing">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="index.html">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>
      <a class="navbar-item" href="biographies.html">
        Presenters
      </a>
      <a class="navbar-item" href="references.html">
        References
      </a>
    </div>
  </div>
</nav>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Presenters. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Presenters</h2>
        <div class="content has-text-justified">
          <p>
            <b>Shichang Zhang</b> (Harvard University) is a postdoctoral fellow at Harvard University. He holds a Ph.D. in Computer Science from the University of California, Los Angeles. His research focuses on AI interpretability, with particular expertise in explainable AI, data attribution, and mechanistic interpretability for large language models (LLMs). His work aims to understand complex feature interactions and model internal mechanisms to develop more explainable and efficient AI systems. His research has applications spanning science, healthcare, and public policy. His recent contributions to the field include developing a unified attribution framework and advancing cross-domain methodologies. His work has appeared in leading venues including NeurIPS, ICML, and ICLR, and has been highlighted in Nature News Feature for its educational impact. He also brings valuable experience organizing workshops at NeurIPS. Website: <a href="https://shichangzh.github.io/">https://shichangzh.github.io/</a>
          </p>
          <p>
            <b>Himabindu Lakkaraju</b> (Harvard University) is an Assistant Professor at Harvard University with appointments in the Business School and the Department of Computer Science. Her research interests lie within the broad area of the algorithmic foundations and societal implications of trustworthy AI. Specifically, she develops machine learning and optimization techniques as well as evaluation frameworks to improve the safety, interpretability, fairness, privacy, and reasoning capabilities of predictive and generative models, including large language models (LLMs). Her recent research deals with exposing the vulnerabilities of various explanation methods and making them more robust. She has also been working with various domain experts to understand the real-world consequences of misleading explanations. She has given tutorials at NeurIPS in 2020 and invited talks at various workshops in ICML, NeurIPS, CVPR, and other top venues. Website: <a href="https://himalakkaraju.github.io/">https://himalakkaraju.github.io/</a>
          </p>
          <p>
            <b>Julius Adebayo</b> (Guide Labs) is the cofounder of Guide Labs, building interpretable AI systems that humans and domain experts can easily audit, steer, and understand. He got his PhD in Computer Science from MIT, where he worked on developing and understanding approaches that seek to make machine learning based systems reliable when deployed. More broadly, he is interested in rigorous approaches to help develop models that are robust to spurious associations, distribution shifts, and align with 'human' values.  His recent work has looked at understanding and assessing popular neural network feature relevance techniques in order to evaluate how faithful these methods are to the model being interpreted. Website: <a href="https://juliusadebayo.com/">https://juliusadebayo.com/</a>
          </p>
        </div>
      </div>
    </div>
    <!--/ Presenters. -->
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
